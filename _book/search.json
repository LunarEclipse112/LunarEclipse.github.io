[{"path":"index.html","id":"welcome","chapter":"Welcome!","heading":"Welcome!","text":"Welcome portfolio. collection different skills projects showcase can done. page contains different group skills stands alone presentation. website work progress, currently still much beginning stages made.","code":""},{"path":"index.html","id":"about-me","chapter":"Welcome!","heading":"About Me","text":"studied Life sciences university applied sciences Utrecht (HU). Within degree specialized bio-molecular research data analysis visualization. passionate biology, molecular life sciences data analysis. work environment can combine interests dream job \n. specialization bio-molecular research data analysis knowledge can bridge lab analysis data scientist.working little bit gather work experience looking forward start Master’s program either Bio-molecular research Data analysis bioinformatics.","code":""},{"path":"guerrilla-analytics.html","id":"guerrilla-analytics","chapter":"Guerrilla Analytics","heading":"Guerrilla Analytics","text":"working together groups using github alone ones silico interface great importance keep consistent organized structure easily find data code. one hand crucial avoid confusion version usage (v4_file instead latestlateslatest_file) established files data named README.txt file explanation METADATA file. hand makes writing code edit, analyse plot data much easier path data files fixed. Guerrilla analytics reproducibility allows anyone quickly understand files data contain helps analysts write easier code deepening file locations.short example set type shown . organized one courses guerrilla analytics format better explain structure. easy work much enjoy looking well organized project.Although course organized properly allot missing items like missing code chunks due running code changes data Rmarkdown instead individual scripts. Note also consists 3 projects, just one. means depth comparison single project, said , depth creates chaos.","code":"fs::dir_tree(here::here(\"daur2/\"))\n\n/home/1686589/daur2/\n├── rna_seq_ipsc\n│   ├── README.txt\n│   ├── code\n│   │   └── Input.R\n│   ├── data\n│   ├── rnaseq_ipsc.Rmd\n│   └── rnaseq_ipsc.html\n├── rnaseq_airway\n│   ├── README.txt\n│   ├── code\n│   │   ├── input.R\n│   │   └── namen.txt\n│   ├── data\n│   │   ├── airway_sampledata.csv\n│   │   ├── bam\n│   │   │   ├── SRR1039508.bam\n│   │   │   ├── SRR1039508.bam.indel.vcf\n│   │   │   ├── SRR1039508.bam.summary\n│   │   │   ├── SRR1039509.bam\n│   │   │   ├── SRR1039509.bam.indel.vcf\n│   │   │   ├── SRR1039509.bam.summary\n│   │   │   ├── SRR1039512.bam\n│   │   │   ├── SRR1039512.bam.indel.vcf\n│   │   │   ├── SRR1039512.bam.summary\n│   │   │   ├── SRR1039513.bam\n│   │   │   ├── SRR1039513.bam.indel.vcf\n│   │   │   ├── SRR1039513.bam.summary\n│   │   │   ├── SRR1039516.bam\n│   │   │   ├── SRR1039516.bam.indel.vcf\n│   │   │   ├── SRR1039516.bam.summary\n│   │   │   ├── SRR1039517.bam\n│   │   │   ├── SRR1039517.bam.indel.vcf\n│   │   │   ├── SRR1039517.bam.summary\n│   │   │   ├── SRR1039520.bam\n│   │   │   ├── SRR1039520.bam.indel.vcf\n│   │   │   ├── SRR1039520.bam.summary\n│   │   │   ├── SRR1039521.bam\n│   │   │   ├── SRR1039521.bam.indel.vcf\n│   │   │   ├── SRR1039521.bam.summary\n│   │   │   └── alignment_statistics.rds\n│   │   ├── counts\n│   │   │   └── read_counts.rds\n│   │   ├── fastq\n│   │   │   ├── SRR1039508_1.fastq.gz\n│   │   │   ├── SRR1039508_2.fastq.gz\n│   │   │   ├── SRR1039509_1.fastq.gz\n│   │   │   ├── SRR1039509_2.fastq.gz\n│   │   │   ├── SRR1039512_1.fastq.gz\n│   │   │   ├── SRR1039512_2.fastq.gz\n│   │   │   ├── SRR1039513.fastq.gz\n│   │   │   ├── SRR1039513_1.fastq.gz\n│   │   │   ├── SRR1039513_2.fastq.gz\n│   │   │   ├── SRR1039516.fastq.gz\n│   │   │   ├── SRR1039516_1.fastq.gz\n│   │   │   ├── SRR1039516_2.fastq.gz\n│   │   │   ├── SRR1039517_1.fastq.gz\n│   │   │   ├── SRR1039517_2.fastq.gz\n│   │   │   ├── SRR1039520.fastq.gz\n│   │   │   ├── SRR1039520_1.fastq.gz\n│   │   │   ├── SRR1039520_2.fastq.gz\n│   │   │   ├── SRR1039521.fastq.gz\n│   │   │   ├── SRR1039521_1.fastq.gz\n│   │   │   ├── SRR1039521_2.fastq.gz\n│   │   │   ├── fastq_dump_downloader.sh\n│   │   │   ├── fastqc.sh\n│   │   │   └── refgenome_downloader.sh\n│   │   ├── fastqc_output\n│   │   │   ├── SRR1039508_1_fastqc.html\n│   │   │   ├── SRR1039508_1_fastqc.zip\n│   │   │   ├── SRR1039508_2_fastqc.html\n│   │   │   ├── SRR1039508_2_fastqc.zip\n│   │   │   ├── SRR1039509_1_fastqc.html\n│   │   │   ├── SRR1039509_1_fastqc.zip\n│   │   │   ├── SRR1039509_2_fastqc.html\n│   │   │   ├── SRR1039509_2_fastqc.zip\n│   │   │   ├── SRR1039512_1_fastqc.html\n│   │   │   ├── SRR1039512_1_fastqc.zip\n│   │   │   ├── SRR1039512_2_fastqc.html\n│   │   │   ├── SRR1039512_2_fastqc.zip\n│   │   │   ├── SRR1039513_1_fastqc.html\n│   │   │   ├── SRR1039513_1_fastqc.zip\n│   │   │   ├── SRR1039513_2_fastqc.html\n│   │   │   ├── SRR1039513_2_fastqc.zip\n│   │   │   ├── SRR1039513_fastqc.html\n│   │   │   ├── SRR1039513_fastqc.zip\n│   │   │   ├── SRR1039516_1_fastqc.html\n│   │   │   ├── SRR1039516_1_fastqc.zip\n│   │   │   ├── SRR1039516_2_fastqc.html\n│   │   │   ├── SRR1039516_2_fastqc.zip\n│   │   │   ├── SRR1039516_fastqc.html\n│   │   │   ├── SRR1039516_fastqc.zip\n│   │   │   ├── SRR1039517_1_fastqc.html\n│   │   │   ├── SRR1039517_1_fastqc.zip\n│   │   │   ├── SRR1039517_2_fastqc.html\n│   │   │   ├── SRR1039517_2_fastqc.zip\n│   │   │   ├── SRR1039520_1_fastqc.html\n│   │   │   ├── SRR1039520_1_fastqc.zip\n│   │   │   ├── SRR1039520_2_fastqc.html\n│   │   │   ├── SRR1039520_2_fastqc.zip\n│   │   │   ├── SRR1039520_fastqc.html\n│   │   │   ├── SRR1039520_fastqc.zip\n│   │   │   ├── SRR1039521_1_fastqc.html\n│   │   │   ├── SRR1039521_1_fastqc.zip\n│   │   │   ├── SRR1039521_2_fastqc.html\n│   │   │   ├── SRR1039521_2_fastqc.zip\n│   │   │   ├── SRR1039521_fastqc.html\n│   │   │   └── SRR1039521_fastqc.zip\n│   │   ├── hg38_genome\n│   │   │   └── GRCh38.primary_assembly.genome.fa\n│   │   └── hg38_index\n│   │       ├── hg38_index.00.b.array\n│   │       ├── hg38_index.00.b.tab\n│   │       ├── hg38_index.files\n│   │       ├── hg38_index.log\n│   │       ├── hg38_index.reads\n│   │       ├── subread-index-sam-186134-meVx1N\n│   │       └── subread-index-sam-193622-AYN0aX\n│   ├── rna_seq.Rmd\n│   └── rna_seq.html\n└── rnaseq_onecut\n    ├── README.txt\n    ├── Rmarkdown\n    │   ├── rnaseq_eind.Rmd\n    │   ├── rnaseq_eind.html\n    │   ├── rnaseq_eind.log\n    │   ├── rnaseq_eind.tex\n    │   ├── v1_Eindopdracht.Rmd\n    │   └── v2_Eindopdracht.Rmd\n    ├── code\n    ├── data\n    └── output\n        ├── 6_volcano_plot-1.png\n        ├── perbase_SRR7866699.png\n        └── perseq_SRR7866699.png"},{"path":"relational-databases.html","id":"relational-databases","chapter":"Relational Databases","heading":"Relational Databases","text":"Working relational databases means many cases communicate using SQL. pull store data important follows small demonstration can done.first start loading required data short analysis. use data gapminder, data set dslabs package use dengue flu data sets.\nloading data need make tidy make easier work R. also make allot easier work compare data load DBeaver using SQL.finish plot simple graphs show bit data merged.","code":"\n############ Load in Data ##############################################\n## Gapminder data from the dslabs package\n  gapdat <- gapminder\n  gapdata_tidy <- gapminder\n## Dengue en flu data \n  dengue_data <- read_csv(here::here(\"data/dengue_data.csv\"), skip = 10)\n  flu_data <- read_csv(here::here(\"data/flu_data.csv\"), skip = 10)\n########################################################################\n############################## Tidy Data ################################\n\n## Gapminder data looks very tidy so no changes there except for the year column, that needs to become Date\n  gapdata_tidy$year <- as.character(gapdata_tidy$year)\n  colnames(gapdat) <- c(\"country\", \"Date\", \"infant_mortality\", \"life_expectancy\", \"fertility\", \"population\", \"gdp\", \"continent\", \"region\")\n\n## flu data tidy:\n  flu_data_tidy <- flu_data %>% pivot_longer(cols = -c(Date),\n                                             names_to = \"country\",\n                                             values_to = \"count_cases\") \n  ## dengue data tidy:\n  dengue_data_tidy <- dengue_data %>% pivot_longer(cols = -c(Date),\n                                             names_to = \"country\",\n                                             values_to = \"values\") \n########################### Export the Data ############################\n\n## Now we are going to write off the tidy data sets as csv and rds to export them later into the database\n  write_csv(gapdat_tidy, path = here::here(\"data/gapdat_tidy.csv\"))\n  write_csv(flu_data_tidy, path = here::here(\"data/flu_tidy.csv\"))\n  write_csv(dengue_data_tidy, path = here::here(\"data/dengue_tidy.csv\"))\n  \n  write_rds(gapdat_tidy, path = here::here(\"data/gapdat_tidy.rds\"))\n  write_rds(flu_data_tidy, path = here::here(\"data/flu_tidy.rds\"))\n  write_rds(dengue_data_tidy, path = here::here(\"data/dengue_tidy.rds\"))\n\n  ## In DBeaver we now make a new database to store the data\nCREATE DATABASE fludata;## Then in SQL we define the primary keys of the tables (Date and country)\nalter table public.flu_data \n    add constraint PK_flu_data primary key (Date, country);\n    \nalter table public.dengue_data \n    add constraint PK_dengue_data primary key (Date, country);\n\nalter table public.gapminer_data \n    add constraint PK_gapminder_data primary key (Date, country);\n\n## And we inspect the data from the table flu_data to check if all went well\nselect * from flu_data;\n######################## Inspect the Data ######################################\n## Now that the data has been stored in the database we can inspect it in R using the connection made\n\n# Shows the tables\ndbListTables(con)\n\n# Shows the table of gaminder_data\ndbGetQuery(con, 'SELECT * FROM gapminder_data')\n####################### Modify the gapminder data ##############################\n# Next we want to join the 3 data frames together based on the year and country columns\n## flu data tidy:\n  flu_data_tidy <- flu_data_tidy %>% separate(col = Date, into = c(\"year\", \"Month\", \"Day\"), sep = \"-\")\n## dengue data tidy:\n  dengue_data_tidy <- dengue_data_tidy  %>% separate(col = Date, into = c(\"year\", \"Month\", \"Day\"), sep =\"-\")\n    \nsic <- dengue_data_tidy %>% full_join(flu_data_tidy, by=c(\"year\",\"country\", \"Day\", \"Month\"))\n\nmerged_dat <- sic %>% full_join(gapdata_tidy, by=c(\"country\", \"year\"))\n#################### Graphs #####################################################\n\n# Now we have a dataframe with the data from all the 3 tables and we can make some exploratory graphs with it \n\n# Actually render good graphs, this is still the basic output..\n\n## Graph of the infant mortality in Bolivia\nmerged_dat %>% filter(country == \"Bolivia\" & year >= 2003) %>% \n  group_by(year, infant_mortality) %>% summarise(mean = mean(infant_mortality, na.rm = TRUE), sdev = sd(infant_mortality, na.rm = TRUE)) %>%\n  ggplot(aes(x = year, y = mean)) +\n  geom_bar(stat = \"identity\", colour = \"black\") +\n  geom_errorbar(aes(ymin = mean-sdev, ymax = mean+sdev), width = .3) +\n  scale_fill_manual(values=c(\"#999999\", \"#E69F00\")) +\n  labs(title = \"Infant mortality rate in Bolivia after 2003\",\n       y= \"Infant mortality rate (per 1000 deaths)\",\n       x= \"Year\")\n\n## Graph of the most populated countries in 1998\nmerged_dat %>% select(population, country, year) %>% filter(year == 1998 & population >= 70000000) %>%\n  ggplot(aes(x = country, y = population)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Most populated countries in 1998\",\n       subtitle = \"Limiting values at below 70M inhabitants\",\n       x = \"Country Name\",\n       y = \"Population\")\n\n## Gdp in asian countries in 1990\nmerged_dat %>% select(gdp, continent, year, country) %>% filter(year == 1990 & continent == \"Asia\") %>% arrange(desc(gdp)) %>%\n  ggplot(aes(x = continent, y = gdp, fill = country)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"GDP of Asian countries in 1990\",\n       x = \"Country in Asia\",\n       y = \"GDP\")"},{"path":"parameters.html","id":"parameters","chapter":"Parameters","heading":"Parameters","text":"page look use parameters Rmarkdown. end use data European Center Disease Control COVID-19 case data. goal create two separate graphs, one showing COVID-19 related cases specified month year country COVID-19 related deaths specified month year country. end make parameters customisable month, year country graphs supposed show.Parameters defined yaml header Rmarkdown documents can used just like variable code. One great advantage can customized fly change function output. case defined three parameters:can change date combinations want country long data input data code work. makes work -though wrote function code custom input function complete Rmarkdown file. handy indeed.page show code can take look parameters used . can find parameters used variables: params$parameter_nameParameters great work save time want change small things code already used . personally prefer writing good functions reusing parameters great tool apply aswell.","code":"\n###################### Load in the Data ########################################\n\n## First lets load in the Data kindly supplied by the ECDC. \n  data <- read_csv(here::here(\"data/covid_data.csv\"))\n\n######################## Data wrangling ########################################\n## Now we are going to change the date data type to date instead of chr.\n  data$dateRep <- as.Date(data$dateRep, \"%d/%m/%Y\")\n\n############################# Graphs ###########################################\n\n## Because the data is already tidy enough we don't need to wrangle further and can simply start plotting the graphs we want.\n  \n# Graph #1, the amount of covid-19 cases in a selected country for a selected period of time\n  data %>% select(month, year, day, cases, countriesAndTerritories, dateRep) %>% \n    filter(dateRep >= as.Date(params$date_from) & dateRep <= as.Date(params$date_until), countriesAndTerritories %in% c(params$country)) %>%\n    ggplot(aes(x=dateRep, y=cases)) + \n    geom_line(aes(color = countriesAndTerritories)) +\n    labs(title= paste(\"Covid-19 Cases in\", params$country),\n         subtitle = paste(params$date_from, params$date_until),\n         x= \"Date\",\n         y= \"Number of Cases\") +\n    scale_color_manual(values=c(\"turquoise3\")) +\n    theme_classic()\n\n# Graph #2, The amount of covid-19 Deaths in a selected country for a selected period of time. If I didn't work with parameters I would have build a function for these two graphs seeing as they are very similar in code. \n  data %>% select(month, year, day, deaths, countriesAndTerritories, dateRep) %>% \n    filter(dateRep >= as.Date(params$date_from) & dateRep <= as.Date(params$date_until), countriesAndTerritories %in% c(params$country)) %>%\n    ggplot(aes(x=dateRep, y=deaths)) + \n    geom_line(aes(color = countriesAndTerritories)) +\n    labs(title= paste(\"Covid-19 Deaths in\", params$country),\n         subtitle = paste(params$date_from, params$date_until),\n         x= \"Date\",\n         y= \"Number of Deaths\") +\n    scale_color_manual(values=\"turquoise4\") +\n    theme_classic()"},{"path":"projects.html","id":"projects","chapter":"Projects","heading":"Projects","text":"","code":""},{"path":"projects.html","id":"noldus-project","chapter":"Projects","heading":"Noldus project","text":"Noldus Inc. (“Noldus | Advance Behavioral Research” (n.d.)) University Applied sciences Utrecht (website HU) worked team 5 create shiny app help analyse data acquired one research products: Erasmus Ladder. Erasmus Ladder setup consists horizontal ladder determine differences behavior mice recording steps made selection sensors. Variations amount steps made type steps made mice can recorded accurately allows statistical analysis determine differences groups.","code":""},{"path":"projects.html","id":"the-application","chapter":"Projects","heading":"The application","text":"application analyses data acquired Erasmus Ladder plots exploratory publication ready graphs together statistical analysis researchers easily interpret results. One challenges creating application figuring kind data interesting researchers. reading articles using device speaking researchers field made selection publication ready graph functions read data formatted Erasmus ladder. also made selection exploratory graphs meant help researches get overview data showing basic information like amount mice used, different groups mice, etc. graphs portray overview things like different types steps mice made different groups.","code":""},{"path":"projects.html","id":"example-graphs","chapter":"Projects","heading":"Example graphs","text":"examples data interesting research purposes looked selection different articles. us important criteria articles use Erasmus ladder mostly interested interpreted data . type graphs used portrayed data important us base decisions graphs want application produce based input data. One first graphs found interesting provides clear visual variances steps made different groups mice (María Fernanda Vinueza Veloz et al. 2015). graph two different groups mice, one Purkinje cell deficiency (Pcd) one control group make runs crossing Erasmus ladder. step recorded type steps determined based distance traveled. page 3517 (Fig. 3) article can observe difference variation steps used might caused due Purkinje cell deficiency.\nVersions step type graphs plotted session can also found research (Sathyanesan Gallo 2019; Sathyanesan et al. 2018). graphs depict decrease variation steps used control groups time. might caused mice learning cross bridge efficiently. different type graph looked reaction mice different ques guide mice device. research (M. F. Vinueza Veloz et al. 2012) gave us fresh look data helped guide decisions data might seen relevant.also looked types cerebellum research (Schonewille et al. 2011) selected data better answer research questions. Although mostly applicable project give insight slight differences can .","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""},{"path":"references.html","id":"pages","chapter":"References","heading":"404 pages","text":"default, users directed 404 page try access webpage found.","code":""},{"path":"references.html","id":"references-1","chapter":"References","heading":"References","text":"","code":""}]
